{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from os import listdir\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let keras load images that might be too small\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_SEVERITY = 1\n",
    "\n",
    "IMG_TGT_SZ = (224, 224)\n",
    "IMGS_BASE_PATH = os.path.join('..', 'datasets', 'COVID-19 Dataset', 'CT', 'COVID')\n",
    "#IMGS_BASE_PATH = os.path.join('..', 'datasets', 'ieee8023')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Severity(Enum):\n",
    "    DEBUG = 1\n",
    "    INFO = 2\n",
    "    WARNING = 3\n",
    "\n",
    "def log_msg(msg, severity=Severity.INFO):\n",
    "    if LOG_SEVERITY <= severity.value:\n",
    "        print(f'{severity.name}: {msg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images, model_preprocess=None):\n",
    "    \"Preprocess a list of image files to be used with a CNN 224x224 model\"\n",
    "    pil_images = [load_img(image, target_size=IMG_TGT_SZ) for image in images]\n",
    "    log_msg(f'Loaded {len(images)} images.')\n",
    "    np_images = np.array([img_to_array(image) for image in pil_images])\n",
    "    log_msg(f'Converted to numpy arrays with shape {np_images.shape}.')\n",
    "    if model_preprocess:\n",
    "        np_images = model_preprocess(np_images)\n",
    "    return np_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primary Execution flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = listdir(IMGS_BASE_PATH)\n",
    "\n",
    "images = [os.path.join(IMGS_BASE_PATH, f) for f in files \n",
    "          if f.endswith(('png', 'PNG', 'jpg', 'JPG', 'jpeg', 'JPEG'))]\n",
    "image_names = [os.path.split(f)[1].rpartition('.')[0] for f in images]\n",
    "\n",
    "start = perf_counter()\n",
    "\n",
    "log_msg(f'Loading {len(image_names)} from {IMGS_BASE_PATH}')\n",
    "log_msg(f'Some example images: {images[:5]}', Severity.DEBUG)\n",
    "np_images = preprocess_images(images, vgg16.preprocess_input)\n",
    "\n",
    "end = perf_counter()\n",
    "log_msg(f'Loading images took {end-start} seconds.', Severity.DEBUG)\n",
    "\n",
    "tfdata = Dataset.from_tensor_slices(np_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_covid = tfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridx, gridy = 3, 4\n",
    "rand_imgs = np.random.randint(len(images), size=(gridx*gridy))\n",
    "rand_files = [images[ndx] for ndx in rand_imgs]\n",
    "plt.figure(figsize=(11, 15))\n",
    "for ndx, img in enumerate(rand_files, 1):\n",
    "    plt.subplot(gridx, gridy, ndx)\n",
    "    plt.imshow(load_img(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 15))\n",
    "for ndx, img in enumerate(rand_files, 1):\n",
    "    plt.subplot(gridx, gridy, ndx)\n",
    "    plt.imshow(load_img(img, target_size=IMG_TGT_SZ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with only cnn-layers\n",
    "model_vgg16_conv = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "input_layer = Input(shape=(*IMG_TGT_SZ, 3), name = 'image_input')\n",
    "output_vgg16_conv = model_vgg16_conv(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the fully-connected layers \n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dense(2, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict images w/ vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16.VGG16()\n",
    "yhat = model.predict(np_images)\n",
    "predictions = vgg16.decode_predictions(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top Predictions by vgg16')\n",
    "print('-'*40)\n",
    "for ndx, name in enumerate(image_names):\n",
    "    print(f'{name}: {predictions[ndx][0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
